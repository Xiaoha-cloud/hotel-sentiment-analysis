{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2_embedding_visualization.ipynb\n",
    "# Purpose: Explore and visualize pretrained Chinese word embeddings with full English output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import KeyedVectors\n",
    "import os\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained word vectors if not loaded already\n",
    "if not os.path.exists(\"embeddings/sgns.zhihu.bigram\"):\n",
    "    with open(\"embeddings/sgns.zhihu.bigram\", 'wb') as new_file, open(\"embeddings/sgns.zhihu.bigram.bz2\", 'rb') as file:\n",
    "        decompressor = bz2.BZ2Decompressor()\n",
    "        for data in iter(lambda: file.read(100 * 1024), b''):\n",
    "            new_file.write(decompressor.decompress(data))\n",
    "\n",
    "# Load model\n",
    "cn_model = KeyedVectors.load_word2vec_format(\"embeddings/sgns.zhihu.bigram\", binary=False, unicode_errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a utility function to visualize first 50 dimensions\n",
    "\n",
    "def plot_word_embedding(word, label):\n",
    "    if word not in cn_model.key_to_index:\n",
    "        print(f\"Word '{word}' not in vocabulary.\")\n",
    "        return\n",
    "    vec = cn_model[word]\n",
    "    df = pd.DataFrame(vec[:50]).T\n",
    "    plt.figure(figsize=(14, 1.5))\n",
    "    sns.heatmap(df, cmap=\"YlGnBu\", cbar=False, square=True)\n",
    "    plt.title(f\"Embedding (first 50 dims): {label}\")\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"Dimensions\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings of selected words (English labels only)\n",
    "words_to_plot = {\n",
    "    \"hotel\": \"\\u9152\\u5e97\",\n",
    "    \"black_tea\": \"\\u7ea2\\u8336\",\n",
    "    \"green_tea\": \"\\u7eff\\u8336\",\n",
    "    \"price\": \"\\u4ef7\\u683c\"\n",
    "}\n",
    "\n",
    "for label, word in words_to_plot.items():\n",
    "    print(f\"Visualizing embedding for: {label}\")\n",
    "    plot_word_embedding(word, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic analogy test with English labels only\n",
    "occupation_words = [\"teacher\", \"accountant\", \"programmer\", \"lawyer\", \"doctor\", \"elderly\"]\n",
    "occupation_chinese = [\"\\u8001\\u5e08\", \"\\u4f1a\\u8ba1\\u5e08\", \"\\u7a0b\\u5e8f\\u5458\", \"\\u5f8b\\u5e08\", \"\\u533b\\u751f\", \"\\u8001\\u4eba\"]\n",
    "odd_index_1 = cn_model.doesnt_match(occupation_chinese)\n",
    "odd_label_1 = occupation_words[occupation_chinese.index(odd_index_1)]\n",
    "print(f\"In the occupation list {occupation_words}, the unrelated word is: {odd_label_1}\")\n",
    "\n",
    "tea_words = [\"tea_leaf\", \"black_tea\", \"dark_tea\", \"white_tea\", \"green_tea\", \"yellow_tea\", \"travel\"]\n",
    "tea_chinese = [\"\\u8336\\u53f6\", \"\\u7ea2\\u8336\", \"\\u9ed1\\u8336\", \"\\u767d\\u8336\", \"\\u7eff\\u8336\", \"\\u9ec4\\u8336\", \"\\u65c5\\u6e38\"]\n",
    "odd_index_2 = cn_model.doesnt_match(tea_chinese)\n",
    "odd_label_2 = tea_words[tea_chinese.index(odd_index_2)]\n",
    "print(f\"In the tea-related list {tea_words}, the unrelated word is: {odd_label_2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between selected terms (displaying in English)\n",
    "similarity_1 = cn_model.similarity(\"\\u7ea2\\u8336\", \"\\u7eff\\u8336\")\n",
    "similarity_2 = cn_model.similarity(\"\\u7ea2\\u8336\", \"\\u4ef7\\u683c\")\n",
    "\n",
    "print(\"Cosine similarity between black_tea and green_tea:\", similarity_1)\n",
    "print(\"Cosine similarity between black_tea and price:\", similarity_2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
